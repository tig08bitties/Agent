#!/usr/bin/env ruby
# frozen_string_literal: true

# Î˜Î•ÎŸÎ£CRIPT Tokenizer & Parser
# Parses multi-jurisdictional instructions into execution tree

require 'json'

module Theoscript
  # Jurisdictional token types
  module Jurisdiction
    GREEK_MATRIX = :greek_matrix          # Î£, Î¦, Î‘, Î›, Î˜, Î”
    SYRIAC_LIFECYCLE = :syriac_lifecycle  # Ü, Ü¬
    ARAMAIC_VIEWPORT = :aramaic_viewport  # ğ¡€, âŸ
    DEMOTIC_DRIFT = :demotic_drift        # ğ“€€, ğ“€€-e, ğ“€€-Ät
    OPERATOR_POWER = :operator_power      # âŠ•, âŠ–
    OPERATOR_CALCULUS = :operator_calculus # âˆ‚, âˆ«
    TAMIL_CASE = :tamil_case              # Case modulation
  end

  # Token definition
  class Token
    attr_reader :type, :jurisdiction, :value, :position

    def initialize(type, jurisdiction, value, position)
      @type = type
      @jurisdiction = jurisdiction
      @value = value
      @position = position
    end

    def to_h
      {
        type: @type,
        jurisdiction: @jurisdiction,
        value: @value,
        position: @position
      }
    end
  end

  # Execution Node (DAG element)
  class ExecutionNode
    attr_accessor :action, :jurisdiction, :timestamp, :dependencies, :completed
    attr_reader :id

    def initialize(id, action, jurisdiction, timestamp, dependencies = [])
      @id = id
      @action = action
      @jurisdiction = jurisdiction
      @timestamp = timestamp
      @dependencies = dependencies
      @completed = false
    end

    def can_execute?(current_t)
      current_t >= @timestamp && @dependencies.all?(&:completed)
    end

    def to_h
      {
        id: @id,
        jurisdiction: @jurisdiction,
        timestamp: @timestamp,
        dependencies: @dependencies.map(&:id),
        completed: @completed
      }
    end
  end

  # Tokenizer
  class Tokenizer
    GREEK_SYMBOLS = %w[Î£ Î¦ Î‘ Î› Î˜ Î”].freeze
    SYRIAC_SYMBOLS = %w[Ü Ü¬].freeze
    ARAMAIC_SYMBOLS = %w[ğ¡€ âŸ].freeze
    DEMOTIC_SYMBOLS = %w[ğ“€€ ğ“€€-e ğ“€€-Ät].freeze
    POWER_OPERATORS = %w[âŠ• âŠ–].freeze
    CALCULUS_OPERATORS = %w[âˆ‚ âˆ«].freeze

    def initialize(input)
      @input = input
      @position = 0
      @tokens = []
    end

    def tokenize
      while @position < @input.length
        char = @input[@position]

        case
        when GREEK_SYMBOLS.include?(char)
          add_token(:matrix_param, Jurisdiction::GREEK_MATRIX, char)
        when SYRIAC_SYMBOLS.include?(char)
          add_token(:lifecycle, Jurisdiction::SYRIAC_LIFECYCLE, char)
        when ARAMAIC_SYMBOLS.include?(char)
          add_token(:viewport, Jurisdiction::ARAMAIC_VIEWPORT, char)
        when char == 'ğ“€€'
          # Check for extended demotic forms
          if @input[@position..@position + 2] == 'ğ“€€-e'
            add_token(:demotic_ergative, Jurisdiction::DEMOTIC_DRIFT, 'ğ“€€-e')
            @position += 2
          elsif @input[@position..@position + 3] == 'ğ“€€-Ät'
            add_token(:demotic_ablative, Jurisdiction::DEMOTIC_DRIFT, 'ğ“€€-Ät')
            @position += 3
          else
            add_token(:demotic_base, Jurisdiction::DEMOTIC_DRIFT, 'ğ“€€')
          end
        when POWER_OPERATORS.include?(char)
          add_token(:power_op, Jurisdiction::OPERATOR_POWER, char)
        when CALCULUS_OPERATORS.include?(char)
          add_token(:calculus_op, Jurisdiction::OPERATOR_CALCULUS, char)
        when char == 'X'
          # Marker for power-up zones
          add_token(:marker_x, :marker, 'X')
        when char.match?(/[A-Z]/)
          # Uppercase identifier (valid in Î˜Î•ÎŸÎ£CRIPT)
          identifier = consume_identifier
          add_token(:identifier, :identifier, identifier)
          next
        when char.match?(/\d/)
          # Numeric value
          number = consume_number
          add_token(:number, :literal, number)
          next
        when char.match?(/\s/)
          # Whitespace (skip)
        else
          # Unknown token (skip or error)
          warn "Warning: Unknown token '#{char}' at position #{@position}"
        end

        @position += 1
      end

      @tokens
    end

    private

    def add_token(type, jurisdiction, value)
      @tokens << Token.new(type, jurisdiction, value, @position)
    end

    def consume_identifier
      start = @position
      @position += 1 while @position < @input.length && @input[@position].match?(/[A-Z0-9_]/)
      @input[start...@position]
    end

    def consume_number
      start = @position
      @position += 1 while @position < @input.length && @input[@position].match?(/[\d.]/)
      @input[start...@position].to_f
    end
  end

  # Parser
  class Parser
    def initialize(tokens)
      @tokens = tokens
      @position = 0
      @execution_tree = []
    end

    def parse
      while @position < @tokens.length
        token = @tokens[@position]

        case token.jurisdiction
        when Jurisdiction::GREEK_MATRIX
          parse_matrix_operation(token)
        when Jurisdiction::SYRIAC_LIFECYCLE
          parse_lifecycle_operation(token)
        when Jurisdiction::ARAMAIC_VIEWPORT
          parse_viewport_operation(token)
        when Jurisdiction::DEMOTIC_DRIFT
          parse_demotic_operation(token)
        when Jurisdiction::OPERATOR_POWER
          parse_power_operation(token)
        when Jurisdiction::OPERATOR_CALCULUS
          parse_calculus_operation(token)
        end

        @position += 1
      end

      @execution_tree
    end

    private

    def parse_matrix_operation(token)
      # Î£, Î¦, Î‘ â†’ Matrix parameters for GPU
      @execution_tree << {
        type: :gpu_matrix_update,
        parameter: token.value,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end

    def parse_lifecycle_operation(token)
      # Ü = start, Ü¬ = terminate
      action = token.value == 'Ü' ? :spawn : :terminate
      @execution_tree << {
        type: :process_lifecycle,
        action: action,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end

    def parse_viewport_operation(token)
      # ğ¡€, âŸ â†’ Viewport anchoring
      @execution_tree << {
        type: :viewport_anchor,
        symbol: token.value,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end

    def parse_demotic_operation(token)
      # ğ“€€, ğ“€€-e, ğ“€€-Ät â†’ Drift elements
      case_type = if token.value == 'ğ“€€-e'
                    :ergative
                  elsif token.value == 'ğ“€€-Ät'
                    :ablative
                  else
                    :base
                  end

      @execution_tree << {
        type: :demotic_drift,
        case: case_type,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end

    def parse_power_operation(token)
      # âŠ• = power-up, âŠ– = decay
      action = token.value == 'âŠ•' ? :power_up : :decay
      @execution_tree << {
        type: :power_modulation,
        action: action,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end

    def parse_calculus_operation(token)
      # âˆ‚ = differential, âˆ« = integral
      action = token.value == 'âˆ‚' ? :monitor : :accumulate
      @execution_tree << {
        type: :calculus_operation,
        action: action,
        jurisdiction: token.jurisdiction,
        position: token.position
      }
    end
  end

  # Zone Analyzer
  class ZoneAnalyzer
    def self.determine_zones(execution_tree, current_t)
      zones = {
        power_up: [],
        decay: [],
        central: nil,
        drift: []
      }

      x_markers = []
      taw_positions = []

      execution_tree.each do |node|
        case node[:type]
        when :power_modulation
          if node[:action] == :power_up
            x_markers << node[:position]
          elsif node[:action] == :decay
            zones[:decay] << node[:position]
          end
        when :process_lifecycle
          taw_positions << node[:position] if node[:action] == :terminate
        when :viewport_anchor
          zones[:central] = node if node[:symbol] == 'âŸ'
        when :demotic_drift
          zones[:drift] << node
        end
      end

      # Create power-up zones between X markers
      x_markers.each_slice(2) do |start, finish|
        zones[:power_up] << { start: start, end: finish } if finish
      end

      # Add decay zones beyond Ü¬ markers
      taw_positions.each do |pos|
        zones[:decay] << { start: pos, end: :infinity }
      end

      zones
    end

    def self.in_zone?(current_t, zones, zone_type)
      return false unless zones[zone_type]

      zones[zone_type].any? do |zone|
        zone.is_a?(Hash) && current_t >= zone[:start] && current_t <= zone[:end]
      end
    end
  end
end

# Example usage
if __FILE__ == $PROGRAM_NAME
  puts "Î˜Î•ÎŸÎ£CRIPT Tokenizer & Parser v1.0"
  puts "=" * 50

  # Example Î˜Î•ÎŸÎ£CRIPT instruction
  instruction = "Ü Î£ Î¦ Î‘ âŠ• X ğ“€€-e Ü¬ âŠ– ğ“€€-Ät âŸ"

  puts "\nInput: #{instruction}"
  puts ""

  # Tokenize
  tokenizer = Theoscript::Tokenizer.new(instruction)
  tokens = tokenizer.tokenize

  puts "Tokens:"
  tokens.each do |token|
    puts "  #{token.type.to_s.ljust(20)} | #{token.jurisdiction.to_s.ljust(25)} | #{token.value}"
  end

  # Parse
  parser = Theoscript::Parser.new(tokens)
  execution_tree = parser.parse

  puts "\nExecution Tree:"
  puts JSON.pretty_generate(execution_tree)

  # Analyze zones
  zones = Theoscript::ZoneAnalyzer.determine_zones(execution_tree, 0.0)

  puts "\nZones:"
  puts JSON.pretty_generate(zones)
end
